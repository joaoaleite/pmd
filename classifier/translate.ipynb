{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_eng = df[df[\"article_language\"] == \"English\"]\n",
    "    df_non_eng = df[df[\"article_language\"] != \"English\"]\n",
    "    return df_eng, df_non_eng\n",
    "\n",
    "\n",
    "def create_translation_records(df: pd.DataFrame, model: str = \"gpt-4o-mini\") -> list:\n",
    "    records = []\n",
    "    total_tokens = 0\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        text = (\n",
    "            f\"{row.article_title} {row.article_text}\"\n",
    "            if pd.notna(row.article_title)\n",
    "            else row.article_text\n",
    "        )\n",
    "        message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Translate the following {row.article_language} text to English. Don't include anything other than the translation: '{text}'.\",\n",
    "        }\n",
    "\n",
    "        record = {\n",
    "            \"custom_id\": str(row.article_id),\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\"model\": model, \"messages\": [message]},\n",
    "        }\n",
    "\n",
    "        num_tokens = len(encoding.encode(message[\"content\"]))\n",
    "        total_tokens += num_tokens\n",
    "        records.append(record)\n",
    "\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Avg tokens per record: {total_tokens / len(records)}\")\n",
    "    return records, total_tokens\n",
    "\n",
    "\n",
    "def estimate_costs(total_tokens: int, model: str = \"gpt-4o-mini\") -> dict:\n",
    "    price_per_token_input = 0.075  # Example input price per 1M tokens for gpt-4o-mini\n",
    "    price_per_token_output = 0.300  # Example output price per 1M tokens for gpt-4o-mini\n",
    "\n",
    "    input_cost = round(total_tokens / 1_000_000 * price_per_token_input, 2)\n",
    "    output_cost = round(total_tokens / 1_000_000 * price_per_token_output, 2)\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    return {\n",
    "        \"input_cost\": f\"{input_cost}$\",\n",
    "        \"output_cost\": f\"{output_cost}$\",\n",
    "        \"total_cost\": f\"{total_cost}$\",\n",
    "    }\n",
    "\n",
    "\n",
    "def save_records_to_jsonl(records: list, file_name: str = \"batch.jsonl\") -> None:\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for record in records:\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "    print(f\"Records saved to {file_name}\")\n",
    "\n",
    "\n",
    "def create_translation_batch(client: OpenAI, file_path: str) -> str:\n",
    "    batch_input_file = client.files.create(file=open(file_path, \"rb\"), purpose=\"batch\")\n",
    "    batch_request = client.batches.create(\n",
    "        input_file_id=batch_input_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": \"Translation Batch\"},\n",
    "    )\n",
    "    return batch_request.id\n",
    "\n",
    "\n",
    "def monitor_batch(client: OpenAI, request_id: str) -> None:\n",
    "    while True:\n",
    "        status = client.batches.retrieve(request_id)\n",
    "        if status.status == \"completed\":\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Status: {status.status}, Request Counts: {status.request_counts}\")\n",
    "            sleep(3)\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "def save_batch_output(client: OpenAI, request_id: str, output_file: str) -> None:\n",
    "    status = client.batches.retrieve(request_id)\n",
    "    file_response = client.files.content(status.output_file_id)\n",
    "    file_response.write_to_file(output_file)\n",
    "    print(f\"Batch results saved to {output_file}\")\n",
    "\n",
    "\n",
    "def load_translated_data(file_path: str) -> pd.DataFrame:\n",
    "    translated_data = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            content = json.loads(line)\n",
    "            article_id = content[\"custom_id\"]\n",
    "            text = content[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            translated_data.append({\"article_id\": article_id, \"text_translated\": text})\n",
    "    return pd.DataFrame(translated_data)\n",
    "\n",
    "\n",
    "def merge_translated_data(\n",
    "    df_eng: pd.DataFrame, df_non_eng: pd.DataFrame, translated_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    df_non_eng = df_non_eng.merge(translated_df, on=[\"article_id\"])\n",
    "    df_non_eng = df_non_eng.drop([\"article_text\", \"article_language\"], axis=1)\n",
    "    df_eng = df_eng.drop([\"article_language\"], axis=1)\n",
    "    df_non_eng[\"article_text\"] = df_non_eng[\"text_translated\"]\n",
    "    df_non_eng = df_non_eng.drop([\"text_translated\"], axis=1)\n",
    "    df_final = pd.concat([df_non_eng, df_eng], ignore_index=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng, df_non_eng = load_data(\"../datasets/raw/euvsdisinfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, total_tokens = create_translation_records(df_non_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = estimate_costs(total_tokens)\n",
    "print(\"Estimated costs:\", costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = records[: len(records) // 2]\n",
    "batch2 = records[len(records) // 2 :]\n",
    "\n",
    "save_records_to_jsonl(batch1, \"batch1.jsonl\")\n",
    "save_records_to_jsonl(batch2, \"batch2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request_id_1 = create_translation_batch(client, \"batch1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_batch(client, batch_request_id_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request_id_2 = create_translation_batch(client, \"batch2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_batch(client, batch_request_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_batch_output(client, batch_request_id_1, f\"result-{batch_request_id_1}.jsonl\")\n",
    "save_batch_output(client, batch_request_id_2, f\"result-{batch_request_id_2}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_df_1 = load_translated_data(f\"result-{batch_request_id_1}.jsonl\")\n",
    "translated_df_2 = load_translated_data(f\"result-{batch_request_id_2}.jsonl\")\n",
    "translated_df = pd.concat([translated_df_1, translated_df_2], ignore_index=True)\n",
    "\n",
    "final_df = merge_translated_data(df_eng, df_non_eng, translated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"../datasets/euvsdisinfo_translated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persuasion_multi_domain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
